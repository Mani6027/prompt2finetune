{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kissflow/prompt2finetune/blob/main/Prompting_Strategy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ub0NTGA6uYuV"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55xgFPWJubs3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "\n",
        "# Make sure you have set the OPENAI_API_KEY environment variable\n",
        "# For Colab, you can use the \"üîë\" icon on the left panel to add your API key as a secret.\n",
        "# Name the secret OPENAI_API_KEY.\n",
        "# If you are running this outside of Colab, you can set it as an environment variable\n",
        "# in your terminal: export OPENAI_API_KEY='your-api-key'\n",
        "# Or you can uncomment the line below and replace 'your-api-key' with your actual key:\n",
        "# os.environ['OPENAI_API_KEY'] = 'your-api-key'\n",
        "\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key= userdata.get('OPENAI_API_KEY'),\n",
        ")\n",
        "\n",
        "model = \"openai/gpt-oss-20b:free\" #\"gpt-4.1-mini-2025-04-14\" #\"gpt-3.5-turbo\"\n",
        "\n",
        "def generate_response(prompt, model=model, max_tokens=150):\n",
        "    \"\"\"\n",
        "    Generates a response from the OpenAI API.\n",
        "\n",
        "    Args:\n",
        "        prompt: The input prompt for the model.\n",
        "        model: The OpenAI model to use (default: \"gpt-3.5-turbo\").\n",
        "        max_tokens: The maximum number of tokens in the generated response.\n",
        "\n",
        "    Returns:\n",
        "        The text of the generated response.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.7, # You can adjust the temperature\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error generating response: {e}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exhg9mv5H6_-"
      },
      "outputs": [],
      "source": [
        "# Product Reviews for Examples - Vacuum Cleaner Reviews with Mixed Emotions\n",
        "REVIEWS = [\n",
        "    # Enthusiastic positive reviews\n",
        "    \"This vacuum cleaner is absolutely AMAZING! üéâ I'm so thrilled with my purchase! It's incredibly lightweight, super powerful, and the battery lasts forever. I cleaned my entire 3-bedroom house on a single charge and still had juice left! The attachments are genius - they make reaching tight spaces a breeze. My floors have never been cleaner. I'm telling all my friends about this! HIGHLY RECOMMENDED!\",\n",
        "\n",
        "    \"I'm genuinely impressed with this vacuum cleaner. After years of struggling with heavy, clunky vacuums, this one is a breath of fresh air. It's so easy to use and maneuver around furniture. The suction power is incredible - it picked up pet hair that my old vacuum couldn't even touch. The battery life is impressive too. Worth every penny!\",\n",
        "\n",
        "    \"OMG, this vacuum is a game-changer! üòç I was skeptical at first, but wow, it exceeded all my expectations. It's so quiet compared to my old one, and the cordless design is liberating. I can finally vacuum without tripping over cords! The attachments are perfect for my car and stairs. I'm in love with this product!\",\n",
        "\n",
        "    # Frustrated negative reviews\n",
        "    \"I'm extremely frustrated with this vacuum cleaner. It's a complete waste of money! The battery dies after just 10 minutes of use - I can't even finish one room! It's also incredibly heavy and awkward to maneuver. The suction is pathetic and it struggles with basic dirt. I'm returning this immediately. Terrible product!\",\n",
        "\n",
        "    \"This vacuum cleaner is a huge disappointment. I had such high hopes based on the reviews, but it's been nothing but trouble. The attachments keep falling off, the battery life is terrible, and it's so loud it scares my pets. I'm really upset about this purchase. Would not recommend to anyone.\",\n",
        "\n",
        "    \"I'm absolutely furious about this vacuum! It's been nothing but problems since day one. The motor makes a horrible grinding noise, the dustbin is tiny and fills up immediately, and the battery is completely unreliable. I feel completely ripped off. This is the worst vacuum I've ever owned!\",\n",
        "\n",
        "    # Analytical neutral reviews\n",
        "    \"This vacuum cleaner has both good and bad points. On the positive side, it's relatively lightweight and the attachments work well for corners. However, the battery life is average - it lasts about 30 minutes, which is enough for a small apartment but not a large house. The suction power is decent for daily cleaning but struggles with deep-pile carpets. It's an okay product for the price, but there might be better options available.\",\n",
        "\n",
        "    \"I have mixed feelings about this vacuum. It does what it's supposed to do, but I'm not blown away. The design is nice and it's easy to store, but the battery life could be better. It works fine for quick cleanups but struggles with heavy-duty cleaning. I'm not sure if I'd buy it again, but it's not terrible either.\",\n",
        "\n",
        "    \"This vacuum is... fine. It gets the job done but nothing more. The build quality seems decent, and it's reasonably priced. However, I've noticed it's not as powerful as I expected, and the dustbin fills up quickly. It's an average product - not great, not terrible. I'll probably keep it since it works, but I'm not excited about it.\",\n",
        "\n",
        "    # Emotional reviews (nostalgic, hopeful, regretful)\n",
        "    \"This vacuum reminds me of the one my grandmother used to have - simple, reliable, and effective. It's not fancy, but it does exactly what you need it to do. I appreciate the straightforward design and the fact that it doesn't have unnecessary bells and whistles. Sometimes the old ways are the best ways.\",\n",
        "\n",
        "    \"I'm hopeful this vacuum will work out better than my last one. So far, it seems to be doing okay, but I'm still in the trial period. The battery life seems decent, and it's definitely lighter than what I had before. Fingers crossed it holds up over time!\",\n",
        "\n",
        "    \"I really regret buying this vacuum cleaner. I should have done more research before purchasing. It's not terrible, but it's definitely not worth the price I paid. I wish I had gone with a different brand or model. Live and learn, I guess.\",\n",
        "\n",
        "    # Technical reviews\n",
        "    \"As someone who's used many vacuums professionally, this one is quite impressive from a technical standpoint. The motor is well-designed and efficient, the filtration system is excellent, and the ergonomics are well thought out. However, the battery management system could be improved, and the noise level is higher than expected. Overall, it's a solid performer with room for improvement.\",\n",
        "\n",
        "    \"I've been testing this vacuum for a month now, and I have to say, it's exceeded my expectations in most areas. The suction power is consistent, the battery life is reliable, and the build quality feels premium. The only issue I've encountered is that the dustbin can be tricky to empty sometimes. But overall, I'm very satisfied with this purchase.\",\n",
        "\n",
        "    # Short and concise reviews\n",
        "    \"Love it! Best vacuum I've ever owned.\",\n",
        "\n",
        "    \"Waste of money. Don't buy this.\",\n",
        "\n",
        "    \"It's okay, nothing special.\",\n",
        "\n",
        "    # Detailed experience reviews\n",
        "    \"After using this vacuum for 6 months, I can confidently say it's been a mixed experience. The initial excitement wore off when I realized the battery life wasn't as advertised. However, the suction power is genuinely impressive, and it handles pet hair better than any vacuum I've used. The attachments are well-designed, though the dustbin could be larger. Overall, it's a good product with some limitations.\",\n",
        "\n",
        "    \"I bought this vacuum during a Black Friday sale and honestly, I'm not sure if it was worth it even at the discounted price. The first month was great - it worked perfectly and I was happy with my purchase. But then the battery started degrading quickly, and now it barely lasts 15 minutes. Customer service was unhelpful too. I'm disappointed but I'll make it work until I can afford a replacement.\"\n",
        "]\n",
        "\n",
        "\n",
        "# For consistency with existing examples\n",
        "REVIEWS_TEXT = \"\\n\\n\".join([f\"Review {i+1}:\\n{review}\" for i, review in enumerate(REVIEWS)])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn-VzZwPH6_-"
      },
      "source": [
        "## Zero-Shot Prompting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73b82b63"
      },
      "outputs": [],
      "source": [
        "# Real-world example: Summarize product reviews with zero-shot prompting.\n",
        "def test_zero_shot(review):\n",
        "    prompt = f\"\"\"\n",
        "Summarize the following product review:\n",
        "\n",
        "Review: {review}\n",
        "\"\"\"\n",
        "    response = generate_response(prompt)\n",
        "    print(f\"Zero-Shot Response :\")\n",
        "    print(response)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "test_zero_shot(REVIEWS_TEXT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tas50rTTH6_-"
      },
      "source": [
        "### Zero-Shot Prompting Description\n",
        "\n",
        "**What it is:** Zero-shot prompting involves giving the model a task without providing any examples or demonstrations. The model relies entirely on its pre-training knowledge to understand and complete the task. This is the most basic form of prompting where you simply describe what you want the model to do.\n",
        "\n",
        "**When to use:** Zero-shot prompting works best for simple, well-defined tasks where the model has strong general knowledge from its training data. It's ideal when you need quick results without spending time on prompt engineering or when dealing with common tasks like basic summarization, translation, or simple Q&A.\n",
        "\n",
        "**Pros:** The main advantages include quick setup with minimal token usage, straightforward implementation that doesn't require example selection, and fast execution since there's only one API call. It's also very flexible and can handle a wide variety of tasks without modification.\n",
        "\n",
        "**Cons:** The primary limitations are less reliable performance on complex or domain-specific tasks, inconsistent output format that may require post-processing, and lower accuracy compared to more sophisticated prompting strategies. The model may also produce unexpected results if the task is ambiguous.\n",
        "\n",
        "**Best for:** Common tasks like basic summarization, translation, simple Q&A, general knowledge questions, and straightforward text processing. It works particularly well when the task is clearly defined and the model has strong prior knowledge about the domain.\n",
        "\n",
        "**Note:** Zero-shot prompting works best with clear, unambiguous instructions. The quality of results depends heavily on how well you can describe the task in natural language.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1395a52"
      },
      "source": [
        "## Few-Shot Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "810fc3ef"
      },
      "outputs": [],
      "source": [
        "# Real-world example: Summarize product reviews with few-shot examples.\n",
        "def test_few_shot(review):\n",
        "    few_shot_prompt = f\"\"\"\n",
        "Summarize the following product reviews:\n",
        "\n",
        "Example Review\n",
        "---\n",
        "Review: This phone is terrible. The battery dies in an hour and the camera is blurry.\n",
        "Summary: Poor battery life and camera quality.\n",
        "\n",
        "Review: I love this laptop! It's fast, lightweight, and the screen is stunning.\n",
        "Summary: Fast, lightweight, and excellent display.\n",
        "---\n",
        "\n",
        "Review: {review}\n",
        "Summary:\n",
        "\"\"\"\n",
        "    response = generate_response(few_shot_prompt)\n",
        "    print(f\"Few-Shot Response:\")\n",
        "    print(response)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Test with all three review types\n",
        "test_few_shot(REVIEWS_TEXT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96OpHzEdH6__"
      },
      "source": [
        "### Few-Shot Prompting Description\n",
        "\n",
        "**What it is:** Few-shot prompting involves providing the model with 2-5 example input-output pairs before asking it to complete a similar task. These examples serve as demonstrations that guide the model's behavior and help it understand the expected format, style, and approach for the specific task.\n",
        "\n",
        "**When to use:** Few-shot prompting is ideal when you need specific output format or style, working with domain-specific patterns, or when the model needs guidance on how to approach a particular type of task. It's particularly effective when you have representative examples that clearly show the desired input-output relationship.\n",
        "\n",
        "**Pros:** The main advantages include better accuracy and consistency compared to zero-shot, helps the model understand exact requirements through concrete examples, and provides more reliable output formatting. It's also relatively simple to implement and doesn't require extensive prompt engineering.\n",
        "\n",
        "**Cons:** The primary limitations include higher token usage due to the included examples, requires careful selection of representative examples, and the quality of results depends heavily on the relevance and quality of the provided examples. Poor examples can actually hurt performance.\n",
        "\n",
        "**Best for:** Formatting tasks, classification problems, domain-specific outputs, maintaining consistent tone or style, and tasks where the pattern is clear but the model needs specific guidance. It works well for tasks like sentiment analysis, text classification, and structured data extraction.\n",
        "\n",
        "**Note:** The quality and relevance of examples directly impact results. Choose examples that are representative of the task and clearly demonstrate the desired input-output relationship. Avoid examples that are too similar to each other or that might confuse the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYqFe1-ptNT5"
      },
      "source": [
        "## Self Reflexion"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Real-world example: Summarize a product review using Reflexion (using positive review for complexity).\n",
        "\n",
        "# Initial prompt\n",
        "initial_review_prompt = f\"Summarize the following product review:\\n\\n{REVIEWS_TEXT}\"\n",
        "\n",
        "initial_review_response = generate_response(initial_review_prompt)\n",
        "print(\"Initial Reflexion Response:\")\n",
        "print(initial_review_response)\n",
        "\n",
        "# Reflection prompt to improve the summary\n",
        "reflection_review_prompt = f\"\"\"\n",
        "Based on the following product review and the initial summary:\n",
        "\n",
        "Review: {REVIEWS_TEXT}\n",
        "\n",
        "Initial Summary: {initial_review_response}\n",
        "\n",
        "Critique the initial summary. Does it capture all the key positive aspects mentioned in the review (lightweight, powerful, long battery life, useful attachments, highly recommended)? Suggest improvements to make the summary more comprehensive and accurate.\n",
        "\"\"\"\n",
        "\n",
        "reflection_on_review = generate_response(reflection_review_prompt)\n",
        "print(\"\\nReflection on Initial Response:\")\n",
        "print(reflection_on_review)\n",
        "\n",
        "# Refined prompt incorporating the reflection\n",
        "refined_review_prompt = f\"\"\"\n",
        "Based on the following product review and the critique of the initial summary, provide a refined and comprehensive summary:\n",
        "\n",
        "Review: {REVIEWS_TEXT}\n",
        "\n",
        "Critique: {reflection_on_review}\n",
        "\n",
        "Refined Summary:\n",
        "\"\"\"\n",
        "\n",
        "refined_review_response = generate_response(refined_review_prompt)\n",
        "print(\"\\nRefined Reflexion Response:\")\n",
        "print(refined_review_response)"
      ],
      "metadata": {
        "id": "l_Ba589oSQmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdQvV1OptXGe"
      },
      "outputs": [],
      "source": [
        "# Review + Reflexion in a single prompt\n",
        "review_to_analyze = REVIEWS_TEXT\n",
        "\n",
        "reflexion_prompt = f\"\"\"\n",
        "Summarize the following product review using a self-reflexion approach:\n",
        "\n",
        "Review: {review_to_analyze}\n",
        "\n",
        "Please follow these steps in your response:\n",
        "\n",
        "1. INITIAL SUMMARY: First, write a draft summary of the review.\n",
        "\n",
        "2. SELF-CRITIQUE: Then, critique your own summary. Consider:\n",
        "   - Are all important features mentioned?\n",
        "   - Is the emotional tone preserved?\n",
        "   - Are specific details included?\n",
        "   - Is the recommendation clear?\n",
        "   - What could be improved?\n",
        "\n",
        "3. REFINED SUMMARY: Finally, provide an improved summary that addresses the issues identified in your critique.\n",
        "\n",
        "Format your response with clear labels for each section.\n",
        "\"\"\"\n",
        "\n",
        "reflexion_response = generate_response(reflexion_prompt, max_tokens=400)\n",
        "print(\"Self Reflexion Response (Single Prompt):\")\n",
        "print(reflexion_response)\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaTJTHmXH6__"
      },
      "source": [
        "### Self Reflexion Description\n",
        "\n",
        "**What it is:** Self Reflexion is a multi-step iterative process where the model first generates an initial response, then critiques its own output, and finally produces a refined version based on the critique. This approach leverages the model's ability to evaluate and improve its own work through explicit self-reflection.\n",
        "\n",
        "**When to use:** Self Reflexion is most effective when quality improvement is critical and you're dealing with complex content that benefits from multiple perspectives. It's ideal for high-stakes content where accuracy and coherence are paramount, such as technical analysis, creative writing, or editorial tasks.\n",
        "\n",
        "**Pros:** The main advantages include significantly higher quality outputs through self-correction, the ability to catch and fix errors that might be missed in a single pass, improved coherence and consistency, and the model's ability to identify its own weaknesses and address them.\n",
        "\n",
        "**Cons:** The primary limitations include multiple API calls making it more expensive, slower execution time due to the iterative nature, and higher token usage. It also requires more complex implementation and may not always lead to improvements if the critique criteria aren't well-defined.\n",
        "\n",
        "**Best for:** High-stakes content like technical documentation, creative writing, editorial tasks, complex analysis, and any situation where the quality of the output is more important than speed or cost. It's particularly effective for tasks that benefit from multiple perspectives or iterative refinement.\n",
        "\n",
        "**Note:** Self Reflexion is most effective when the critique criteria are explicitly defined and the model is given clear guidance on what aspects to evaluate. The quality of the final output depends heavily on the effectiveness of the self-critique step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2f0ded4"
      },
      "source": [
        "## Chain of Thought Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsM6s_jfsduO"
      },
      "outputs": [],
      "source": [
        "# Real-world example: Summarize a product review using Chain of Thought (using neutral review for balanced reasoning).\n",
        "\n",
        "chain_of_thought_prompt = f\"\"\"\n",
        "Summarize the following product review, thinking step by step:\n",
        "\n",
        "Review: {REVIEWS_TEXT}\n",
        "\n",
        "Final Summary of Review:\n",
        "\n",
        "Note: Write down your thought process as you progress step-by-step.\n",
        "\"\"\"\n",
        "\n",
        "chain_of_thought_response = generate_response(chain_of_thought_prompt, max_tokens=300) # Increased max_tokens for detailed steps\n",
        "print(\"Chain of Thought Response:\")\n",
        "print(chain_of_thought_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKjvQULmH6__"
      },
      "source": [
        "### Chain of Thought Prompting Description\n",
        "\n",
        "**What it is:** Chain of Thought prompting requires the model to explicitly show its step-by-step reasoning process before providing the final answer. The model breaks down complex problems into smaller, manageable steps and shows its thinking process, making the reasoning transparent and traceable.\n",
        "\n",
        "**When to use:** Chain of Thought is most effective for complex reasoning tasks, mathematical problems, multi-step logic problems, debugging tasks, and any situation where the reasoning process is as important as the final answer. It's particularly useful when you need to understand how the model arrived at its conclusion.\n",
        "\n",
        "**Pros:** The main advantages include significantly better accuracy on complex tasks, transparent reasoning that allows for debugging and verification, easier identification of where the model might be going wrong, and the ability to follow the logical progression of the model's thinking.\n",
        "\n",
        "**Cons:** The primary limitations include longer outputs that consume more tokens, potentially slower processing due to the detailed reasoning, and the possibility of exposing flawed reasoning processes. It may also be overkill for simple tasks.\n",
        "\n",
        "**Best for:** Math problems, logic puzzles, code debugging, analytical reasoning, complex problem-solving, and any task where step-by-step thinking is beneficial. It's particularly effective when combined with phrases like \"Let's think step by step\" or \"Show your work.\"\n",
        "\n",
        "**Note:** Chain of Thought is particularly effective when the model is explicitly prompted to show its reasoning. The quality of the reasoning process often correlates with the accuracy of the final answer, making it a powerful tool for complex problem-solving.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d706558"
      },
      "source": [
        "## Tree of Thoughts Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "784d307c"
      },
      "outputs": [],
      "source": [
        "# Real-world example: Summarize a product review using a simulated Tree of Thoughts.\n",
        "# Note: A true Tree of Thoughts implementation is more complex and would involve\n",
        "# exploring multiple reasoning paths and evaluating them. This is a simplified simulation.\n",
        "\n",
        "def tree_of_thoughts_prompting(initial_thought_prompt, expansion_prompt, evaluation_prompt, steps=2):\n",
        "    \"\"\"\n",
        "    Simulates a basic Tree of Thoughts approach.\n",
        "\n",
        "    Args:\n",
        "        initial_thought_prompt: The initial prompt to generate a starting thought.\n",
        "        expansion_prompt: Prompt to generate subsequent thoughts based on previous ones.\n",
        "        evaluation_prompt: Prompt to evaluate the generated thoughts.\n",
        "        steps: Number of expansion steps to simulate.\n",
        "\n",
        "    Returns:\n",
        "        The evaluated best thought or a summary of the process.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        thoughts = [generate_response(initial_thought_prompt)]\n",
        "        print(\"Initial Thought:\", thoughts[0])\n",
        "\n",
        "        for step in range(steps):\n",
        "            new_thoughts = []\n",
        "            for thought in thoughts:\n",
        "                expansion_response = generate_response(f\"{expansion_prompt}\\n\\nPrevious thought: {thought}\")\n",
        "                # Simple split to simulate multiple thoughts\n",
        "                expanded_thoughts = [t.strip() for t in expansion_response.split('\\n') if t.strip()]\n",
        "                new_thoughts.extend(expanded_thoughts)\n",
        "            thoughts = new_thoughts\n",
        "            print(f\"\\nThoughts after step {step + 1}:\")\n",
        "            for i, thought in enumerate(thoughts):\n",
        "                print(f\"  Thought {i+1}: {thought}\")\n",
        "\n",
        "        # Simple evaluation: Ask the model to pick the best thought or summarize\n",
        "        evaluation_response = generate_response(f\"{evaluation_prompt}\\n\\nThoughts to evaluate:\\n\" + \"\\n\".join([f\"- {t}\" for t in thoughts]))\n",
        "\n",
        "        return evaluation_response\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "# Example usage with the product review summarization (using positive review - too expensive for multiple)\n",
        "initial_thought_prompt = \"Generate an initial thought about summarizing a product review.\"\n",
        "expansion_prompt = \"Expand on the following thought to generate alternative approaches for summarizing a product review.\"\n",
        "evaluation_prompt = f\"Review the following thoughts for summarizing a product review and provide the best summary based on the original review: {REVIEWS_TEXT}\"\n",
        "\n",
        "\n",
        "tree_of_thoughts_response = tree_of_thoughts_prompting(initial_thought_prompt, expansion_prompt, evaluation_prompt, steps=2)\n",
        "print(\"\\nTree of Thoughts Simulation Result:\")\n",
        "print(tree_of_thoughts_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61bz4gweH7AA"
      },
      "source": [
        "### Tree of Thoughts Prompting Description\n",
        "\n",
        "**What it is:** Tree of Thoughts prompting explores multiple reasoning paths simultaneously, evaluates different approaches, and selects the best solution. It's like having the model brainstorm multiple solutions and then pick the most promising one, similar to how humans might approach complex problems by considering various options.\n",
        "\n",
        "**When to use:** Tree of Thoughts is ideal when multiple valid approaches exist for solving a problem, when creative problem-solving is needed, or when optimization is required. It's particularly effective for strategic planning, complex decision-making, and tasks where exploring the solution space thoroughly is beneficial.\n",
        "\n",
        "**Pros:** The main advantages include thorough exploration of the solution space, finding optimal or creative solutions that might be missed with single-path approaches, better handling of ambiguous problems, and the ability to evaluate trade-offs between different approaches.\n",
        "\n",
        "**Cons:** The primary limitations include very high cost due to multiple API calls (often 10-50x more expensive than other methods), significantly slower execution, complex implementation requirements, and the need for sophisticated evaluation mechanisms to compare different approaches.\n",
        "\n",
        "**Best for:** Strategic planning, creative brainstorming, complex optimization problems, decision-making tasks, and any situation where exploring multiple approaches is valuable. It's particularly effective for problems with no clear single solution path.\n",
        "\n",
        "**Note:** This implementation is a simplified simulation of Tree of Thoughts. Production implementations would use more sophisticated evaluation mechanisms, parallel processing, and advanced pruning strategies to manage costs while maintaining effectiveness.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c83c571"
      },
      "source": [
        "## Meta Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00d6a430"
      },
      "outputs": [],
      "source": [
        "# Real-world example: Summarize product reviews using Meta Prompting.\n",
        "def test_meta_prompting(review):\n",
        "    meta_prompt = f\"\"\"\n",
        "You are an expert in summarizing product reviews. Your goal is to provide a concise and informative summary of the given review, focusing only on the key positive and negative aspects mentioned.\n",
        "\n",
        "Here is the product review:\n",
        "Review: {review}\n",
        "\n",
        "Provide the summary in the following format:\n",
        "Summary: [Your concise summary here]\n",
        "\"\"\"\n",
        "    response = generate_response(meta_prompt)\n",
        "    print(f\"Meta Prompting Response\")\n",
        "    print(response)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Test with all three review types\n",
        "test_meta_prompting(REVIEWS_TEXT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tILojSzZH7AA"
      },
      "source": [
        "### Meta Prompting Description\n",
        "\n",
        "**What it is:** Meta prompting assigns the model an explicit role with structured instructions and specific output format requirements. It's like giving the model a job description and clear guidelines on how to perform that job, ensuring consistent behavior across interactions and adherence to specific requirements.\n",
        "\n",
        "**When to use:** Meta prompting is most effective when you need consistent behavior across multiple interactions, have complex task requirements, or are building production systems where reliability and consistency are crucial. It's ideal for API integrations, automated systems, and any situation where the model needs to maintain a specific persona or approach.\n",
        "\n",
        "**Pros:** The main advantages include clear expectations that lead to more consistent outputs, improved task adherence through explicit role definition, better output formatting through structured instructions, and the ability to fine-tune behavior for specific use cases.\n",
        "\n",
        "**Cons:** The primary limitations include the need for careful prompt engineering to define roles effectively, potential over-constraint that might limit creativity, and the requirement to test and refine role definitions for optimal performance.\n",
        "\n",
        "**Best for:** Production systems, API integrations, specific output formats, role-based tasks, and any situation where consistency and reliability are more important than creativity. It works particularly well when combined with other strategies for production use.\n",
        "\n",
        "**Note:** Meta prompting works best when the role definition is clear and specific. The quality of results depends heavily on how well you can articulate the desired behavior and output format. It's often most effective when combined with other prompting strategies.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "tYqFe1-ptNT5",
        "e2f0ded4",
        "7d706558"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}